{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mhcc-data-complete-balanced.csv\u001b[m\u001b[m hcc-stages.txt\n",
      "\u001b[34mhcc-dataset\u001b[m\u001b[m                    hccSurvivalPrediction.ipynb\n",
      "hcc-stages.csv\n",
      "/Users/test-august/Google Drive/HCC ML\n",
      "Training examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>-0.04750</td>\n",
       "      <td>0.016062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.383743</td>\n",
       "      <td>0.456916</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>0.499890</td>\n",
       "      <td>0.451969</td>\n",
       "      <td>0.307080</td>\n",
       "      <td>0.180866</td>\n",
       "      <td>0.34921</td>\n",
       "      <td>0.266132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.516000</td>\n",
       "      <td>-0.53500</td>\n",
       "      <td>-0.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108250</td>\n",
       "      <td>-0.33500</td>\n",
       "      <td>-0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>-0.13500</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.352000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender    Alcohol  Cirrhosis    Smoking   Diabetes    Obesity  \\\n",
       "count  96.000000  96.000000  96.000000  96.000000  96.000000  96.000000   \n",
       "mean    0.822917   0.708333   0.875000   0.447917   0.281250   0.104167   \n",
       "std     0.383743   0.456916   0.332455   0.499890   0.451969   0.307080   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     1.000000   0.000000   1.000000   0.000000   0.000000   0.000000   \n",
       "50%     1.000000   1.000000   1.000000   0.000000   0.000000   0.000000   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   0.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             Age    Nodule      Stage  \n",
       "count  96.000000  96.00000  96.000000  \n",
       "mean    0.012344  -0.04750   0.016062  \n",
       "std     0.180866   0.34921   0.266132  \n",
       "min    -0.516000  -0.53500  -0.648000  \n",
       "25%    -0.108250  -0.33500  -0.148000  \n",
       "50%     0.032000  -0.13500   0.102000  \n",
       "75%     0.156000   0.46500   0.164500  \n",
       "max     0.388000   0.46500   0.352000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation examples summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>-0.031839</td>\n",
       "      <td>-0.018871</td>\n",
       "      <td>-0.075419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.401610</td>\n",
       "      <td>0.425024</td>\n",
       "      <td>0.300537</td>\n",
       "      <td>0.505879</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>0.373878</td>\n",
       "      <td>0.216182</td>\n",
       "      <td>0.349377</td>\n",
       "      <td>0.310869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.612000</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>-0.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.070500</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>-0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>-0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.352000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender    Alcohol  Cirrhosis    Smoking   Diabetes    Obesity  \\\n",
       "count  31.000000  31.000000  31.000000  31.000000  31.000000  31.000000   \n",
       "mean    0.806452   0.774194   0.903226   0.451613   0.419355   0.161290   \n",
       "std     0.401610   0.425024   0.300537   0.505879   0.501610   0.373878   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     1.000000   1.000000   1.000000   0.000000   0.000000   0.000000   \n",
       "50%     1.000000   1.000000   1.000000   0.000000   0.000000   0.000000   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   0.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             Age     Nodule      Stage  \n",
       "count  31.000000  31.000000  31.000000  \n",
       "mean   -0.031839  -0.018871  -0.075419  \n",
       "std     0.216182   0.349377   0.310869  \n",
       "min    -0.612000  -0.335000  -0.648000  \n",
       "25%    -0.070500  -0.335000  -0.398000  \n",
       "50%     0.032000  -0.135000  -0.148000  \n",
       "75%     0.101000   0.465000   0.102000  \n",
       "max     0.279000   0.465000   0.352000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>96.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.59375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.49371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Class\n",
       "count  96.00000\n",
       "mean    0.59375\n",
       "std     0.49371\n",
       "min     0.00000\n",
       "25%     0.00000\n",
       "50%     1.00000\n",
       "75%     1.00000\n",
       "max     1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation targets summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.486373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Class\n",
       "count  31.000000\n",
       "mean    0.645161\n",
       "std     0.486373\n",
       "min     0.000000\n",
       "25%     0.000000\n",
       "50%     1.000000\n",
       "75%     1.000000\n",
       "max     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Passing a dictionary input to a Sequential Model which doesn't have FeatureLayer as the first layer is an error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e15fdbc9e7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m model.fit(trainDS,\n\u001b[1;32m    197\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalDS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m           epochs=5)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2769\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mFeatureLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m     \"\"\"\n\u001b[0;32m-> 2771\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_input_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_input_attrs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2796\u001b[0m         \u001b[0;31m# We assert that the first layer is a FeatureLayer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feature_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2798\u001b[0;31m           raise ValueError('Passing a dictionary input to a Sequential Model '\n\u001b[0m\u001b[1;32m   2799\u001b[0m                            \u001b[0;34m'which doesn\\'t have FeatureLayer as the first layer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m                            ' is an error.')\n",
      "\u001b[0;31mValueError\u001b[0m: Passing a dictionary input to a Sequential Model which doesn't have FeatureLayer as the first layer is an error."
     ]
    }
   ],
   "source": [
    "# Hepatocellular Carcinoma Patient Survival Prediction\n",
    "# Andrea Mazzocchi\n",
    "# v1 September 18, 2019\n",
    "\n",
    "# Objective: \n",
    "\"\"\"Predict patient survival (yes/no) based on condition of liver (pressence of cirrhosis, nodules), lifestyle\n",
    "(obesity, smoking, diabetes), and standard measures (biological sex, age).\"\"\"\n",
    "\n",
    "# Hypothesis:\n",
    "\"\"\"It is hypothesized that the data set will allow for predicition of survival (yes/no) with up to \n",
    "85% accuracy using condition of live, lifestyle, and standard measures factors.\"\"\"\n",
    "\n",
    "# Data Background: \n",
    "\"\"\"Publicly available data set from Kaggle entitled, \"HCC dataset: Hepatocellular Carcinoma Dataset\", \n",
    "uploaded by user mrsantos. The data contains 50 categories, 9 of which will be used for this study.\n",
    "\n",
    "Features: age (20-93), gender (male/female, 0/1), cirrhosis (neg/pos, 0/1), nodules (0-5), \n",
    "          obesity (neg/pos, 0/1), smoking (neg/pos, 0/1), diabetes (neg/pos, 0/1), alcohol (neg/pos, 0/1),\n",
    "          stage(1-4)\n",
    "Label: class (dead/alive, 0/1)\n",
    "\"\"\"\n",
    "\n",
    "# Sample Size: 164 patients, 159 valid\n",
    "\n",
    "\n",
    "# Plan of execution:\n",
    "\"\"\"\n",
    "1) Set objective and hypothesis, select categories/measures from dataset \n",
    "2) Import relevent libraries\n",
    "3) Pre-process downloaded dataset (remove unused categories,remove incomplete sets, normalize non-binary data)\n",
    "4) Randomly divide set into training (3/5), validation(1/5), and test(1/5) sets\n",
    "5) Utiliize TensorFlow for logistic regression (train model)\n",
    "6) Determine loss with training and validation data sets\n",
    "7) Improve model through L1 regularization, L2 regularization, and learning rate\n",
    "8) Use test set for final model analysis\n",
    "9) Calculate final loss of model (training vs test) and output ROC and AUC curves\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 1 - Set objective and hypothesis, select categories/measures from dataset (shown above)\n",
    "\n",
    "# Step 2 - Import relevent libraries\n",
    "\n",
    "#from _future_ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display \n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "# Step 3 - Pre-process downloaded dataset\n",
    "\n",
    "# List contents in current directory\n",
    "!ls\n",
    "\n",
    "# Print working directory \n",
    "! pwd\n",
    "\n",
    "# Opening dataset from directory \n",
    "hccSet = pd.read_csv(\"hcc-data-complete-balanced.csv\")\n",
    "\n",
    "# Removing unused categories (done by creating a dataframe that only includes categories of interest)\n",
    "hccSet = hccSet[['Gender','Alcohol','Cirrhosis','Smoking','Diabetes','Obesity','Age','Nodule','Class']]\n",
    "hccSet.shape\n",
    "\n",
    "\n",
    "# Adding cancer stage at diagnosis\n",
    "stage = pd.read_fwf('hcc-stages.txt')\n",
    "stage.to_csv('hcc-stages.csv')\n",
    "stage = pd.DataFrame(stage)\n",
    "stage.columns=['Stage']\n",
    "stageRow = len(stage)\n",
    "hccSet[:-(204-stageRow)] # would like to change out use of 204\n",
    "hccSet['Stage'] = stage\n",
    "\n",
    "# Re-index Columns\n",
    "columnsTitles = [\"Gender\",\"Alcohol\",\"Cirrhosis\",\"Smoking\",\"Diabetes\",\"Obesity\",\"Age\",\"Nodule\",\"Stage\",\"Class\"]\n",
    "hccSet = hccSet.reindex(columns=columnsTitles)\n",
    "\n",
    "\n",
    "# Removing incomplete sets\n",
    "hccSet = hccSet.replace('?', np.NaN)\n",
    "hccSet = hccSet.dropna()\n",
    "hccSet = hccSet.reset_index()\n",
    "\n",
    "# Make all points floating\n",
    "hccSet = hccSet.astype(\"float\")\n",
    "\n",
    "# Scale non-binary features to -1<x<1  (age, nodule, stage) - done by iterating through columns to determine if binary\n",
    "for column in hccSet:\n",
    "    a = hccSet[column].max() - hccSet[column].min()\n",
    "    if a > 1 and column != 'index':\n",
    "        mean = hccSet[column].mean()\n",
    "        hccSet[column] = (hccSet[column].apply(lambda x: (float(x)-mean)/a))\n",
    "    else:\n",
    "        continue;\n",
    "hccSet = hccSet.round(3)\n",
    "\n",
    "# Further feature engineering for this data set is not required as all data is as integers or floating point\n",
    "\n",
    "## Step 4 - Randomly divide set into training (~3/5), validation(~1/5), and test(~1/5) sets\n",
    "\n",
    "# Reindex so data is randomized (already random, but will further randomize in case there is unknown bias)\n",
    "hccSet = hccSet.reindex(np.random.permutation(hccSet.index))\n",
    "\n",
    "\n",
    "\n",
    "# Select training examples (~3/5, 97 examples)\n",
    "trainSet = hccSet.head(96)\n",
    "remainSet = hccSet.tail(62)\n",
    "# Select validation examples (~1/5, 31 examples)\n",
    "valSet = hccSet.head(31)\n",
    "# Select test examples (~1/5, 31 examples)\n",
    "testSet = hccSet.tail(31)\n",
    "\n",
    "# Separate features from targets (Class = target)\n",
    "# Targets\n",
    "hccTarg = hccSet[['Class']].copy()\n",
    "\n",
    "# Features\n",
    "hccFeat = hccSet[['Gender','Alcohol','Cirrhosis','Smoking','Diabetes','Obesity','Age','Nodule','Stage']].copy()\n",
    "\n",
    "\n",
    "trainTarg = hccTarg.head(96)\n",
    "trainFeat = hccFeat.head(96)\n",
    "\n",
    "remainTarg = hccTarg.tail(62) \n",
    "remainFeat = hccFeat.tail(62)\n",
    "\n",
    "\n",
    "valTarg = remainTarg.head(31)\n",
    "valFeat = remainFeat.head(31)\n",
    "\n",
    "\n",
    "testTarg = remainTarg.tail(31)\n",
    "testFeat = remainFeat.tail(31)\n",
    "\n",
    "# Check sets for similar representation\n",
    "print(\"Training examples summary:\")\n",
    "display.display(trainFeat.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "display.display(valFeat.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "display.display(trainTarg.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "display.display(valTarg.describe())\n",
    "\n",
    "## Step 5 - Utiliize TensorFlow for logistic regression (train model)\n",
    "\n",
    "# Creating feature columns\n",
    "featureColumns = []\n",
    "\n",
    "for header in ['Gender','Alcohol','Cirrhosis','Smoking','Diabetes','Obesity','Age','Nodule','Stage','Class']:\n",
    "  featureColumns.append(tf.feature_column.numeric_column(header))\n",
    "\n",
    "\n",
    "# Creating feature layers\n",
    "featureLayer = tf.keras.layers.DenseFeatures(featureColumns)\n",
    "\n",
    "# Creating batch size\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Class')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.repeat().batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "batch_size = 10\n",
    "trainDS = df_to_dataset(trainSet, batch_size=batch_size)\n",
    "valDS = df_to_dataset(valSet, shuffle=False, batch_size=batch_size)\n",
    "testDS = df_to_dataset(testSet, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Train model\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainDS,\n",
    "          validation_data=valDS,\n",
    "          epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
